{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('oceans_12Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_sentiment(rating):\n",
    "    if(rating > 5):\n",
    "        return 'Positive'\n",
    "    elif (rating == 5):\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overall_sentiment'] = df['ratings'].apply(lambda x: give_sentiment(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre Trained VADER sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_sentiment(text):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = analyser.polarity_scores(text)\n",
    "    if(sentiment_score['compound'] > 0):\n",
    "        return 'Positive'\n",
    "    elif(sentiment_score['compound'] == 0):\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_sentiment'] = df['reviews_clean'].apply(lambda x: vader_sentiment(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of incorrectly classified reviews: 0.516\n"
     ]
    }
   ],
   "source": [
    "print('Proportion of incorrectly classified reviews: ' + str(df[df['overall_sentiment'] != df['vader_sentiment']].size/df.size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([w for w in nltk.word_tokenize(text) if w not in stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of incorrectly classified reviews: 0.636\n"
     ]
    }
   ],
   "source": [
    "df['tokenized_no_stopwords_reviews'] = df['reviews_clean'].apply(lambda x: remove_stopwords(x))\n",
    "df['vader_stopwords_classification'] = df['tokenized_no_stopwords_reviews'].apply(\n",
    "    lambda x: vader_sentiment(x))\n",
    "print('Proportion of incorrectly classified reviews: ' +\n",
    "      str(df[df['overall_sentiment'] != df['vader_stopwords_classification']].size/df.size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "text_vectorized = cv.fit_transform(df['tokenized_no_stopwords_reviews'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(text_vectorized, df['overall_sentiment'], test_size = 0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(xtrain, ytrain)\n",
    "pred = mnb.predict(xtest)\n",
    "accuracy_score = metrics.accuracy_score(pred, ytest)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.51\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,2))\n",
    "text_vectorized2 = cv.fit_transform(df['tokenized_no_stopwords_reviews'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    text_vectorized2, df['overall_sentiment'], test_size=0.2, random_state=42)\n",
    "mnb.fit(xtrain, ytrain)\n",
    "pred = mnb.predict(xtest)\n",
    "accuracy_score = metrics.accuracy_score(pred, ytest)\n",
    "print(accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word):\n",
    "    lem = WordNetLemmatizer()\n",
    "    return lem.lemmatize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmatized_text'] = df['tokenized_no_stopwords_reviews'].apply(\n",
    "    lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 1))\n",
    "text_vectorized3 = cv.fit_transform(df['lemmatized_text'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    text_vectorized3, df['overall_sentiment'], test_size=0.2, random_state=42)\n",
    "mnb.fit(xtrain, ytrain)\n",
    "pred = mnb.predict(xtest)\n",
    "accuracy_score = metrics.accuracy_score(pred, ytest)\n",
    "print(accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie downside many reviewers think think tries ambitious fault trying top predecessor oceans eleven evident gimmick raise level building three inches using underwater hydraulic contraptions couldnt follow logistics escapade much less think feasible sheer audacity idea sounded compelling get come linus caldwells matt damon idea lookie loo bundle joy brilliant else would come idea julia roberts impersonating julia roberts movie almost good bruce campbell portraying elvis presley turn impersonates elvis presley impersonator bubba ho tep try wrapping heard around one julia roberts provides number outing reunites usual gang idiots first movie good see cheadle got credit flick time around agree theres lot confused story youre paying attention need glued picture throughout noteworthy scenes include tesss roberts encounter bruce willis vincent cassels turn slow motion break dancer laser field jump end caper turns almost secondary zaniness involved none believable believable oceans eleven come right leave brain door enjoy flick camaraderie fun involved ocean crew easier way'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['lemmatized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.41\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "cv = CountVectorizer(ngram_range=(2, 2\n",
    "                                  ))\n",
    "text_vectorized4 = cv.fit_transform(df['lemmatized_text'])\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    text_vectorized4, df['overall_sentiment'], test_size=0.2, random_state=42)\n",
    "svc = LinearSVC()\n",
    "svc.fit(xtrain, ytrain)\n",
    "print('accuracy score : ' + str(metrics.accuracy_score(svc.predict(xtest), ytest)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
